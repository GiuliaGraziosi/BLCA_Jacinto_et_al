# Load required libraries 
# if not installed use install.packages('libraryname')
install.packages('R2OpenBUGS')
install.packages('epiR')
install.packages('coda')
install.packages('mcmcplots')
install.packages("rjags")
install.packages("runjags")
want = c("parallel","compute.es")
have = want %in% rownames(installed.packages())
if ( any(!have) ) { install.packages( want[!have] ) }

# first or in RStudio > Tools menu > Install packages (from CRAN or zip)
library(epiR) #for epi.betabuster
library(R2OpenBUGS) #for driving OpenBUGS from R
library(coda) #for reading and diagnostics of MCMC chains
library(mcmcplots) #for plotting
library(runjags)
library(rjags) #it works only if you donwloaded JAGS online https://sourceforge.net/projects/mcmc-jags/
testjags()
library(parallel)
library(compute.es)

setwd("/Users/giuliagraziosi/Desktop/2024_Beisnoitia/R_codes")

# create a data set as a matrix (rep of N positives and N negatives for each test, binomial outcome 0 or 1 repeated X times)
C_PCR <- c(rep(1, 31), rep(0, 23)) 
length(C_PCR)
N_S_PCR <- c(rep(1, 25), rep(0, 6), rep(1, 12), rep(0,11))
length(N_S_PCR)
HIS <- c(rep(1,7),rep(0,18),rep(1,1),rep(0,5),rep(1,0),rep(0,12),rep(1,0),rep(0,11))
length(HIS)

dat <- data.frame(C_PCR,N_S_PCR,HIS)
m.ca2 <- as.matrix(dat)

dump("m.ca2") #It creates the following m.ca with 0 and 1 (neg or pos) values according to the test; after you run this code you need to Open -> dumpdata.R in your folder

#On the dumpdata.R you need to add N <- 54, that represents total sample size in this case, plus a vector with number of "1" equal to N

## Define data

N <- 54
m.ca2 <-
  structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 
              1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 
              0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 
              0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(54L, 
                                                                                 3L), .Dimnames = list(NULL, c("C_PCR", "N_S_PCR", "HIS")))





ones <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)

################################################################################################
## Bayesian latent-class model code for three diagnostic tests 
################################################################################################

#######################################################
##Definition of the variables in the model - Codependence btw C_PCR and N_S_PCR
#######################################################

hw_3t_1p <- c("var p[N], q[N,8], pr[N], L[N], checks[N,16]; 

# N    <- observations (N = 54 cattle)
# p    <- individual samples
# q    <- different combinations of test results
# prc  <- prevalence
# s    <- test sensitivities
# c    <- test specificities
# covs <- conditional dependency between tests sensitivities
# covc <- conditional dependency between tests specificities
# m.ca <- data set name

model {
  
  for(i in 1:N){
    
    q[i,1]<-prc*(s1*s2*s3+covs12)+(1-prc)*((1-c1)*(1-c2)*(1-c3)+covc12);
    q[i,2]<-prc*(s1*s2*(1-s3)+covs12)+(1-prc)*((1-c1)*(1-c2)*c3+covc12);
    q[i,3]<-prc*(s1*(1-s2)*s3-covs12)+(1-prc)*((1-c1)*c2*(1-c3)-covc12);
    q[i,4]<-prc*(s1*(1-s2)*(1-s3)-covs12)+(1-prc)*((1-c1)*c2*c3-covc12);
    q[i,5]<-prc*((1-s1)*s2*s3-covs12)+(1-prc)*(c1*(1-c2)*(1-c3)-covc12);
    q[i,6]<-prc*((1-s1)*s2*(1-s3)-covs12)+(1-prc)*(c1*(1-c2)*c3-covc12);
    q[i,7]<-prc*((1-s1)*(1-s2)*s3+covs12)+(1-prc)*(c1*c2*(1-c3)+covc12);
    q[i,8]<-prc*((1-s1)*(1-s2)*(1-s3)+covs12)+(1-prc)*(c1*c2*c3+covc12);
    
    #######################################################
    ## Check and correct potential errors of probabilities exceeding (0,1) bounds 
    #######################################################
    
    checks[i,1]<-   s1*s2*s3+covs12;
    checks[i,2]<-   (1-c1)*(1-c2)*(1-c3)+covc12;
    checks[i,3]<-  s1*s2*(1-s3)+covs12;
    checks[i,4]<-  (1-c1)*(1-c2)*c3+covc12;
    checks[i,5]<-  s1*(1-s2)*s3-covs12;
    checks[i,6]<-  (1-c1)*c2*(1-c3)-covc12;
    checks[i,7]<-  s1*(1-s2)*(1-s3)-covs12;
    checks[i,8]<-  (1-c1)*c2*c3-covc12;
    checks[i,9]<-  (1-s1)*s2*s3-covs12;
    checks[i,10]<- c1*(1-c2)*(1-c3)-covc12;
    checks[i,11]<- (1-s1)*s2*(1-s3)-covs12;
    checks[i,12]<- c1*(1-c2)*c3-covc12;
    checks[i,13]<- (1-s1)*(1-s2)*s3+covs12;
    checks[i,14]<- c1*c2*(1-c3)+covc12;
    checks[i,15]<- (1-s1)*(1-s2)*(1-s3)+covs12;
    checks[i,16]<- c1*c2*c3+covc12;
    
    valid[i]<- step(1-q[i,1])*step(q[i,1])*
      step(1-q[i,2])*step(q[i,2])*
      step(1-q[i,3])*step(q[i,3])* 
      step(1-q[i,4])*step(q[i,4])*
      step(1-q[i,5])*step(q[i,5])*
      step(1-q[i,6])*step(q[i,6])*
      step(1-q[i,7])*step(q[i,7])*
      step(1-q[i,8])*step(q[i,8])*
      step(1-checks[i,1])*step(checks[i,1])*
      step(1-checks[i,2])*step(checks[i,2])*
      step(1-checks[i,3])*step(checks[i,3])*
      step(1-checks[i,4])*step(checks[i,4])*
      step(1-checks[i,5])*step(checks[i,5])*
      step(1-checks[i,6])*step(checks[i,6])*
      step(1-checks[i,7])*step(checks[i,7])*
      step(1-checks[i,8])*step(checks[i,8])*
      step(1-checks[i,9])*step(checks[i,9])*
      step(1-checks[i,10])*step(checks[i,10])*
      step(1-checks[i,11])*step(checks[i,11])*
      step(1-checks[i,12])*step(checks[i,12])*
      step(1-checks[i,13])*step(checks[i,13])*
      step(1-checks[i,14])*step(checks[i,14])*
      step(1-checks[i,15])*step(checks[i,15])*
      step(1-checks[i,16])*step(checks[i,16]);
    
    #######################################################
    ## Contribution to the likelihood for each observation
    #######################################################
    
    L[i]<- equals(valid[i],1)*(
      equals(m.ca [i,1],1)*equals(m.ca[i,2],1)*equals(m.ca [i,3],1)*q[i,1]
      + equals(m.ca [i,1],1)*equals(m.ca[i,2],1)*equals(m.ca [i,3],0)*q[i,2]
      + equals(m.ca [i,1],1)*equals(m.ca[i,2],0)*equals(m.ca [i,3],1)*q[i,3]
      + equals(m.ca [i,1],1)*equals(m.ca[i,2],0)*equals(m.ca [i,3],0)*q[i,4]
      + equals(m.ca [i,1],0)*equals(m.ca[i,2],1)*equals(m.ca [i,3],1)*q[i,5]
      + equals(m.ca [i,1],0)*equals(m.ca[i,2],1)*equals(m.ca [i,3],0)*q[i,6]
      + equals(m.ca [i,1],0)*equals(m.ca[i,2],0)*equals(m.ca [i,3],1)*q[i,7]
      + equals(m.ca [i,1],0)*equals(m.ca[i,2],0)*equals(m.ca [i,3],0)*q[i,8]
    ) +(1-equals(valid[i],1)) *(1e-14);
    
    
    #######################################################
    ## Trick to ensure the probabilities are always less than 1
    #######################################################
    
    p[i] <- L[i] / 1;## divided by a constant just to ensure all p's <1
    ones[i] ~ dbern(p[i]);     
    
  }
  
  #######################################################
  ## Definition of model priors which should be modified for sensitivity analysis.
  ## Assuming a uniform distribution for the covariance terms
  ## Assuming a beta distribution for prevalence and test accuracy estimates.
  ## Parameters of the beta prior distribution obtained by Betabuster
  ## https://betabuster.software.informer.com/1.0/
  #######################################################
  
  covs12 ~ dunif(-1,1);
  covc12 ~ dunif(-1,1);
  
  prc ~ dbeta(2.346, 4.141) ;  ##Mode 0.30, Min 0.10 (95% confidence), Quantiles: 5%, 95%	(0.1, 0.675) 
c1  ~ dbeta(42.111, 1.839) ;        ## SP Mode 0.98, Min 0.90 (95% confidence),   Quantiles: 5%, 95%	(0.9, 0.993)          
c2  ~ dbeta(1,1);   
c3  ~ dbeta(1,1);              
s1  ~ dbeta(15.034, 2.559)  ;##SE Mode 0.90, Min. 0.70 (95% confidence), Quantiles: 5%, 95%	(0.7, 0.963)              
s2  ~ dbeta(1,1) ;        
s3  ~ dbeta(1,1);  
  logL<-sum(log(p[1:N])); 
  
}") 

# Set different starting values for the three different chains to assess convergence

inits1 = list(".RNG.name" ="base::Mersenne-Twister",
              ".RNG.seed" = 100022)
inits2 = list(".RNG.name" ="base::Mersenne-Twister",
              ".RNG.seed" = 300022)
inits3 = list(".RNG.name" ="base::Mersenne-Twister",
              ".RNG.seed" = 500022)


# Run the model with the package runjags 
results <- run.jags(hw_3t_1p,
                    data=list(N=N, m.ca=m.ca2, ones=ones),
                    inits=list(inits1, inits2, inits3), 
                    n.chains = 3,
                    burnin = 10000,
                    sample = 100000,
                    adapt = 1000,
                    monitor = c('prc','c1','c2','c3','s1','s2','s3','covs12','dic', 'deviance'))

# Model checking and diagnostics:
# 1. visually checking the trace plots for mixing of the three chains
# 2. checking the Gelman-Rubin convergence diagnostics,
# the psrf (potential scale reduction factor) should be < 1.1 
results ##Report MEANS and Lower and Upper95, DIC for model fit assessment

plot(results) 

plot(results,
     vars = list("prc", "c1","c2", "c3"),
     layout = c(5,4),
     plot.type = c("trace", "histogram", "autocorr", "ecdf"))


plot(results,
     vars = list("s1", "s2", "s3"),
     layout = c(5,4),
     plot.type = c("trace", "histogram", "autocorr", "ecdf"))

# And the density plots as in analysis.R:
plot(results, plot.type='density', vars=c('c1', 'c2','c3','s1','s2','s3'))

round(results$summary$quantiles,3)*100

#Extract DIC
extract.runjags(results, what = 'dic') #To obtain mean deviance and penalized deviance
